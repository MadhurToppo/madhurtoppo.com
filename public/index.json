[{"content":"What You\u0026rsquo;ll Find Here Hello and welcome! I\u0026rsquo;m excited to share my thoughts and experiences in software engineering, cloud-native development, and technology insights.\nIn this blog, I\u0026rsquo;ll be covering:\nSoftware Engineering Best Practices: Lessons learned from building scalable enterprise systems Cloud-Native Development: Microservices, containerization, and modern deployment strategies AI Integration: Working with Spring AI, RAG systems, and LLM implementations Technology Tutorials: Practical guides and how-tos Industry Insights: Thoughts on the evolving tech landscape Stay tuned for more content, and feel free to reach out if you have any questions or topics you\u0026rsquo;d like me to cover!\n","permalink":"https://madhurtoppo.com/posts/welcome/","summary":"\u003ch1 id=\"what-youll-find-here\"\u003eWhat You\u0026rsquo;ll Find Here\u003c/h1\u003e\n\u003cp\u003eHello and welcome! I\u0026rsquo;m excited to share my thoughts and experiences in software engineering, cloud-native development, and technology insights.\u003c/p\u003e\n\u003cp\u003eIn this blog, I\u0026rsquo;ll be covering:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSoftware Engineering Best Practices\u003c/strong\u003e: Lessons learned from building scalable enterprise systems\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCloud-Native Development\u003c/strong\u003e: Microservices, containerization, and modern deployment strategies\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAI Integration\u003c/strong\u003e: Working with Spring AI, RAG systems, and LLM implementations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTechnology Tutorials\u003c/strong\u003e: Practical guides and how-tos\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIndustry Insights\u003c/strong\u003e: Thoughts on the evolving tech landscape\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStay tuned for more content, and feel free to reach out if you have any questions or topics you\u0026rsquo;d like me to cover!\u003c/p\u003e","title":"Welcome to My Blog"},{"content":"The 12 Factors — and Beyond Building Cloud Native Applications with Spring Boot involves more than just containerization and orchestration. It’s about designing software that thrives in dynamic cloud environments — scalable, resilient, observable, and secure.\nLet’s explore the 12 Factors and Beyond, adapted for modern Spring-based systems.\n1. One Codebase, One Application Every application should have a single codebase tracked in version control (e.g., Git, Subversion).\n✅ Each environment (dev, staging, prod) deploys from the same source, not different branches. Keeping codebase in a common source (main) for all environments.\ngit init git add . git commit -m \u0026#34;initial commit\u0026#34; git push origin main 💡 Tip: Use Git branching strategies (GitFlow or Trunk-based development) for cleaner CI/CD pipelines.\n2. API First Design APIs before implementing business logic. With an API-first approach, teams can develop independently while maintaining strong contracts between services. Spring tools like SpringDoc OpenAPI or Swagger can automatically generate API documentation and contracts.\n@RestController @RequestMapping(\u0026#34;/api/v1/customers\u0026#34;) public class CustomerController { @GetMapping(\u0026#34;/{id}\u0026#34;) public ResponseEntity\u0026lt;Customer\u0026gt; getCustomer(@PathVariable Long id) { return ResponseEntity.ok(new Customer(id, \u0026#34;Alice\u0026#34;, \u0026#34;alice@example.com\u0026#34;)); } } \u0026lt;!-- pom.xml --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-starter-webmvc-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Access API docs at: http://localhost:8080/swagger-ui.html\n3. Dependency Management Declare and manage dependencies explicitly using a manifest file such as pom.xml (Maven) or build.gradle (Gradle).\n\u0026lt;!-- pom.xml --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 💡 Use a single build tool and lock dependency versions for reproducible builds.\n4. Design, Build, Release, and Run A Cloud Native app moves through four key stages:\ni. Design: Decide tech stack, dependencies, and architecture.\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ii. Build: Package source code and dependencies into an immutable artifact (JAR/Docker image).\nmvn clean package Dockerfile\nFROM eclipse-temurin:21-jdk COPY target/*.jar app.jar ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;,\u0026#34;/app.jar\u0026#34;] Then build the Docker image:\ndocker build -t cloudnative-app:1.0.0 . iii. Release: Tag and push the release image with version info.\ndocker tag cloudnative-app:1.0.0 myrepo/cloudnative-app:1.0.0 docker push myrepo/cloudnative-app:1.0.0 You could store configuration separately in a .env or Kubernetes ConfigMap:\nAPP_ENV=prod DB_URL=jdbc:postgresql://db:5432/demo iv. Run: Run the released image in a controlled environment.\nLocal run:\ndocker run -d -p 8080:8080 --env-file .env myrepo/cloudnative-app:1.0.0 Kubernetes deployment:\napiVersion: apps/v1 kind: Deployment metadata: name: cloudnative-app spec: replicas: 2 template: spec: containers: - name: cloudnative-app image: myrepo/cloudnative-app:1.0.0 envFrom: - configMapRef: name: app-config 💡 CI/CD Integration:\nUse tools like GitHub Actions, Jenkins, or Argo CD to automate these four stages — from building the Docker image to deploying it to your Kubernetes cluster.\n5. Configuration, Credentials, and Code Keep configuration and secrets outside the codebase — preferably in environment variables or a config server.\n# application.properties spring.datasource.url=${DB_URL} spring.datasource.username=${DB_USER} spring.datasource.password=${DB_PASS} Set them in your shell or Kubernetes Secret:\nexport DB_URL=jdbc:postgresql://db:5432/demo export DB_USER=admin export DB_PASS=secret Or use Spring Cloud Config for centralized management.\n6. Logs Applications should write logs to stdout/stderr and not handle storage.\n@Slf4j @RestController public class LogController { @GetMapping(\u0026#34;/process\u0026#34;) public String process() { log.info(\u0026#34;Processing request at {}\u0026#34;, LocalDateTime.now()); return \u0026#34;done\u0026#34;; } } External systems (e.g., Loki, ELK Stack) aggregate, process, and visualize logs for analysis. Combine with Spring Boot Actuator and Grafana Loki for structured logging.\n🧠 In Docker or Kubernetes, logs can be collected automatically via kubectl logs or Loki.\n7. Disposability Applications must be fast to start and graceful to shut down.\n# application.properties server.shutdown=graceful spring.lifecycle.timeout-per-shutdown-phase=30s @EventListener(ContextClosedEvent.class) public void onShutdown() { log.info(\u0026#34;Cleaning up before shutdown...\u0026#34;); } In failure scenarios, new instances should automatically spin up (resilience). Docker and Kubernetes make disposability easy with readiness/liveness probes and auto-scaling.\nlivenessProbe: httpGet: path: /actuator/health/liveness port: 8080 8. Backing Services Treat databases, message brokers, caches, and APIs as attached resources — easily replaceable without code changes.\nExample: swapping MySQL for PostgreSQL or RabbitMQ for Kafka should not require refactoring.\n@Service public class MessageService { private final RabbitTemplate rabbitTemplate; public MessageService(RabbitTemplate rabbitTemplate) { this.rabbitTemplate = rabbitTemplate; } public void sendMessage(String msg) { rabbitTemplate.convertAndSend(\u0026#34;queue_name\u0026#34;, msg); } } 9. Environment Parity Maintain minimal differences across development, staging, and production. Bridging gaps ensures reliability:\nTime Gap: Faster deployment cycles. People Gap: Developers and Ops share ownership (DevOps). Tools Gap: Same tools and dependencies across environments. Example: Use Docker Compose locally and Kubernetes in production with similar configurations.\n# docker-compose.yml services: app: image: cloudnative-app environment: - SPRING_PROFILES_ACTIVE=dev db: image: postgres 10. Administrative Processes Treat DB migrations, batch jobs, and cron tasks as one-off processes tracked in the same codebase.\njava -jar app.jar --spring.profiles.active=prod \\ --spring.flyway.enabled=true Use Flyway or Liquibase for version-controlled schema migrations.\n-- V1__create_table.sql CREATE TABLE customer (id SERIAL PRIMARY KEY, name VARCHAR(50)); 11. Port Binding Applications should self-contain an embedded server and expose services via a unique port.\nIn Spring Boot:\nserver.port=8080 The app becomes a service that can be consumed by others via port binding.\nAccess at http://localhost:8080\n12. Stateless Processes Adopt a share-nothing architecture — state belongs in databases or caches, not in-memory. This allows horizontal scaling without session loss. Use Spring Session with Redis or Hazelcast for distributed session management.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; @EnableRedisHttpSession public class SessionConfig { } 13. Concurrency Achieve scalability by running multiple concurrent processes. Leverage JVM thread pools, WebFlux reactive programming, or Kubernetes replicas. Example: Use @Async in Spring or reactive pipelines with Project Reactor.\n@Async public void processTask() { log.info(\u0026#34;Processing in thread: {}\u0026#34;, Thread.currentThread().getName()); } @EnableAsync @SpringBootApplication public class CloudNativeApp {} 14. Telemetry Cloud Native apps must be observable — monitor metrics, logs, traces, and health.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Tools:\nPrometheus for metrics Grafana for visualization Loki for logs Tempo or Jaeger for tracing Integrate with Spring Boot Actuator for /metrics, /health, and /prometheus endpoints.\n# application.yml management: endpoints: web: exposure: include: health, metrics, prometheus 15. Authentication \u0026amp; Authorization Secure APIs and services using OAuth 2.0, OpenID Connect, or JWT tokens.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-oauth2-resource-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Use Spring Security or delegate to an API Gateway like Spring Cloud Gateway for centralized security enforcement.\n@Bean SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { return http .authorizeHttpRequests(auth -\u0026gt; auth .requestMatchers(\u0026#34;/actuator/**\u0026#34;).permitAll() .anyRequest().authenticated()) .oauth2ResourceServer(OAuth2ResourceServerConfigurer::jwt) .build(); } 🌩️ Beyond the 12 Factors\nModern Cloud Native development goes further:\nResilience: Circuit breakers, retries, and bulkheads via resilience4j. Observability: Distributed tracing with Spring Cloud Sleuth or Micrometer Tracing. GitOps: Declarative deployments with Argo CD. Service Meshes: Secure and monitor network traffic with Istio or Linkerd. Cloud Native Spring in Action is not just a checklist — it’s a mindset of automation, scalability, and resilience that drives how modern applications are built and operated.\n","permalink":"https://madhurtoppo.com/posts/cloud-native/cloud-native-applications/","summary":"\u003ch2 id=\"the-12-factors--and-beyond\"\u003eThe 12 Factors — and Beyond\u003c/h2\u003e\n\u003cp\u003eBuilding Cloud Native Applications with Spring Boot involves more than just\ncontainerization and orchestration. It’s about designing software that thrives\nin dynamic cloud environments — scalable, resilient, observable, and secure.\u003c/p\u003e\n\u003cp\u003eLet’s explore the 12 Factors and Beyond, adapted for modern Spring-based systems.\u003c/p\u003e\n\u003ch3 id=\"1-one-codebase-one-application\"\u003e1. One Codebase, One Application\u003c/h3\u003e\n\u003cp\u003eEvery application should have a single codebase tracked in version control (e.g., Git,\nSubversion).\u003c/p\u003e\n\u003cp\u003e✅ Each environment (dev, staging, prod) deploys from the same source, not different branches. Keeping codebase in a common source (main) for all environments.\u003c/p\u003e","title":"Cloud Native Applications"},{"content":"Observability and Monitoring in Modern Spring Boot Applications Modern distributed systems are complex — dozens of services, asynchronous communication, and dynamic scaling make understanding what’s happening inside the system harder than ever. That’s where Observability and Monitoring come in.\nWhile Monitoring tells us that something is wrong, Observability helps us understand why it’s wrong. In a typical Spring Boot microservice setup, observability involves 3 core pillars:\n🧭 1. Metrics — Quantifying System Health Metrics give a numerical insights about system behavior — CPU usage, request latency, error rates, etc.\nIn a Spring Boot ecosystem, we can easily enable metrics using Micrometer:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Once added, the application automatically exposes metrics at the /actuator/prometheus endpoint.\nPrometheus regularly scrapes these metrics and stores them in its time-series database. From there, Grafana connects to Prometheus to visualize dashboards and create alerts.\n✅ Metrics Pipeline Summary:\nSpring Boot (Micrometer) → /actuator/prometheus → Prometheus → Grafana This pipeline gives a real-time visibility into the application performance — we can chart request rates, error percentages, JVM memory, and more.\n🔍 2. Traces — Following a Request Across Services Metrics are great, but they don’t tell the story of one specific request. That’s where Distributed Tracing comes in.\nWith OpenTelemetry, the Spring Boot services can be automatically instrumented by adding the OpenTelemetry Java Agent or SDK.\nThis agent captures:\nHTTP client \u0026amp; server spans Database queries Messaging (Kafka, RabbitMQ) interactions Traces are then exported in OTLP (OpenTelemetry Protocol) format to the OpenTelemetry Collector, which forwards them to Tempo, a distributed tracing backend.\nGrafana integrates with Tempo, allowing to visualize traces and understand latency across microservices.\n✅ Tracing Pipeline Summary:\nSpring Boot (OpenTelemetry) → OTLP → OpenTelemetry Collector → Tempo → Grafana This pipeline helps answer why a request was slow — bottlenecks can be pinpointed down to individual database calls.\n🧾 3. Logs — Contextual Insights for Debugging Logs capture the raw narrative of what’s happening inside the application. When properly structured and correlated with traces, they become a powerful debugging tool.\nUsing the Loki Logback Appender, the Spring Boot apps can send logs directly to Loki:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.github.loki4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;loki-logback-appender\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; Each log entry is labeled (e.g., service=order-service, level=INFO) for fast querying in Grafana. When integrated with OpenTelemetry, the logs also include traceId and spanId in the MDC — allowing them to correlate logs with traces.\n✅ Logs Pipeline Summary:\nSpring Boot (Loki Appender) → Loki → Grafana Now, a single Grafana dashboard can be used to:\nVisualize metrics trends Explore distributed traces Drill down into correlated logs 🎯 Bringing It All Together When these three pipelines work in harmony — Metrics, Traces, and Logs — a full-stack Monitoring and Observability can be achieved.\nMetrics → What’s happening? Traces → Where is it happening? Logs → Why is it happening? Together, they form a feedback loop that enables proactive monitoring, faster incident resolution, and deeper insight into the system’s behavior.\n🚀 Final Takeaway Monitoring and Observability aren’t tools — they are a mindset. They are about building systems that tell their own stories. With Spring Boot, Micrometer, OpenTelemetry, Prometheus, Loki, Tempo, and Grafana, we have all the pieces to make that story visible.\n","permalink":"https://madhurtoppo.com/posts/cloud-native/observability-and-monitoring/","summary":"\u003ch1 id=\"observability-and-monitoring-in-modern-spring-boot-applications\"\u003eObservability and Monitoring in Modern Spring Boot Applications\u003c/h1\u003e\n\u003cp\u003eModern distributed systems are complex — dozens of services, asynchronous\ncommunication, and dynamic scaling make understanding what’s happening inside\nthe system harder than ever. That’s where \u003cstrong\u003eObservability\u003c/strong\u003e and \u003cstrong\u003eMonitoring\u003c/strong\u003e\ncome in.\u003c/p\u003e\n\u003cp\u003eWhile \u003cstrong\u003eMonitoring\u003c/strong\u003e tells us \u003cem\u003ethat\u003c/em\u003e something is wrong, \u003cstrong\u003eObservability\u003c/strong\u003e helps\nus understand \u003cem\u003ewhy\u003c/em\u003e it’s wrong. In a typical Spring Boot microservice setup,\nobservability involves 3 core pillars:\u003c/p\u003e\n\u003ch2 id=\"-1-metrics--quantifying-system-health\"\u003e🧭 1. Metrics — Quantifying System Health\u003c/h2\u003e\n\u003cp\u003eMetrics give a numerical insights about system behavior — CPU usage, request latency, error rates, etc.\u003c/p\u003e","title":"Observability and Monitoring"},{"content":"A Deep Dive into the Java Virtual Machine (JVM): From Source Code toExecution The Java Virtual Machine (JVM) is at the heart of the Java ecosystem. It’s an abstract computing machine that enables Java applications to run anywhere—without needing platform-specific recompilation. But how does Java code actually go from .java files to running processes? Let’s break down the full lifecycle.\nSource Code → Bytecode: Every Java program begins as source code written in .java files. These files are compiled by the Java Compiler (javac) into bytecode, stored in .class files. Source Code Example: public class HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello, JVM!\u0026#34;); } } Compilation Command:\njavac HelloWorld.java Output: HelloWorld.class containing platform-independent bytecode This bytecode is the intermediate representation of the program — not directly executable by the OS, but readable by the JVM.\nJVM Architecture Overview: The JVM has three main subsystems that handle execution:\nClass Loader Subsystem Runtime Data Areas Execution Engine JVM Class Loader Subsystem: The Class Loader is responsible for dynamically loading Java classes into memory during runtime. It works in three main steps:\nLoading: Reads .class files and brings them into the JVM. Linking: Verifies bytecode for security and correctness, prepares memory for class variables, and resolves symbolic references. Initialization: Executes static initializers (static { } blocks) and assigns static variable values. The JVM uses a delegation hierarchy:\nBootstrap Class Loader – Loads core Java classes (java.lang.*, java.util.*) Extension Class Loader – Loads classes from the extension directories Application Class Loader – Loads classes from the user’s classpath JVM Runtime Data Areas: Once classes are loaded, the JVM allocates memory in several runtime areas:\nMethod Area: Stores class structures, method data, and runtime constant pool. Heap: Allocates memory for objects (managed by Garbage Collector). Java Stack: Holds local variables and partial results for each thread. PC Register: Keeps track of the current instruction being executed. Native Method Stack: Supports native (non-Java) code execution through JNI.\nJVM Execution Engine: The Execution Engine is where bytecode becomes actual machine instructions. It has three major components:\nInterpreter: Reads and executes bytecode line by line. JIT (Just-In-Time) Compiler: Converts frequently executed bytecode (“hot code”) into native machine code to boost performance. Garbage Collector (GC): Automatically manages memory, freeing up unused objects from the heap. Together, the Execution Engine and JIT compiler make the JVM fast and adaptive, optimizing execution during runtime. The Complete Flow:\nSource Code (.java) ↓ Compiler (javac) ↓ Bytecode (.class) ↓ Class Loader Subsystem ↓ Runtime Data Areas ↓ Execution Engine (Interpreter + JIT) ↓ Native Machine Code → Execution Conclusion: The JVM is far more than a runtime—it’s a sophisticated platform that abstracts hardware details, manages memory automatically, and optimizes performance on the fly. By transforming source code into bytecode and executing it efficiently through the class loader and execution engine, the JVM remains one of the most powerful virtualized environments in modern computing. ","permalink":"https://madhurtoppo.com/posts/java/jvm-deep-dive/","summary":"\u003ch2 id=\"a-deep-dive-into-the-java-virtual-machine-jvm-from-source-code-toexecution\"\u003eA Deep Dive into the Java Virtual Machine (JVM): From Source Code toExecution\u003c/h2\u003e\n\u003cp\u003eThe Java Virtual Machine (JVM) is at the heart of the Java ecosystem.\nIt’s an abstract computing machine that enables Java applications to run\nanywhere—without needing platform-specific recompilation. But how does Java code\nactually go from .java files to running processes? Let’s break down the full\nlifecycle.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eSource Code → Bytecode:\u003c/strong\u003e Every Java program begins as source code written\nin .java files. These files are compiled by the Java Compiler (javac) into\nbytecode, stored in .class files. Source Code Example:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-java\" data-lang=\"java\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003eclass\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eHelloWorld\u003c/span\u003e {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e   \u003cspan style=\"color:#66d9ef\"\u003epublic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003estatic\u003c/span\u003e \u003cspan style=\"color:#66d9ef\"\u003evoid\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003emain\u003c/span\u003e(String\u003cspan style=\"color:#f92672\"\u003e[]\u003c/span\u003e args) {\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e       System.\u003cspan style=\"color:#a6e22e\"\u003eout\u003c/span\u003e.\u003cspan style=\"color:#a6e22e\"\u003eprintln\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Hello, JVM!\u0026#34;\u003c/span\u003e);\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e   }\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e}\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eCompilation Command:\u003c/p\u003e","title":"JVM Deep Dive"}]